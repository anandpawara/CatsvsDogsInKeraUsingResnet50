{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this tutorial we will be using pretrained model on out dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 224\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dropout,Flatten,Dense\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "import keras as K\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting training and validation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'data/dogscats/train/'\n",
    "validation_data_dir = 'data/dogscats/valid/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                preprocessing_function=preprocess_input,\n",
    "                shear_range=0.2,\n",
    "                zoom_range = 0.2,\n",
    "                horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "                preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size = (sz,sz),\n",
    "                                                   batch_size = batch_size,class_mode = 'binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                       shuffle = False,\n",
    "                                                       target_size = (sz,sz),\n",
    "                                                       batch_size = batch_size,\n",
    "                                                       class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are modifying last layer of the model to give give output as per our need\n",
    "0 means it is a cat and 1 means dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights = 'imagenet',include_top = False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation='relu')(x)\n",
    "prediction = Dense(1,activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=base_model.inputs,output = prediction)\n",
    "for layer in base_model.layers:layer.trainable = False\n",
    "model.compile(optimizer = 'rmsprop',loss = 'binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "359/359 [==============================] - 119s 330ms/step - loss: 0.1926 - acc: 0.9479 - val_loss: 0.0667 - val_acc: 0.9829\n",
      "Epoch 2/3\n",
      "359/359 [==============================] - 107s 299ms/step - loss: 0.0864 - acc: 0.9700 - val_loss: 0.0706 - val_acc: 0.9808\n",
      "Epoch 3/3\n",
      "359/359 [==============================] - 107s 297ms/step - loss: 0.0634 - acc: 0.9778 - val_loss: 0.0796 - val_acc: 0.9829\n",
      "CPU times: user 20min 11s, sys: 30.5 s, total: 20min 42s\n",
      "Wall time: 5min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f848c51fdd8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(train_generator,\n",
    "                    train_generator.n // batch_size,\n",
    "                   epochs = 3,\n",
    "                   workers = 4,\n",
    "                   validation_data = validation_generator,\n",
    "                   validation_steps = validation_generator.n // batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting model to train only last few layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_at = 140\n",
    "for layer in model.layers[:split_at]: layer.trainable = False\n",
    "for layer in model.layers[split_at:]: layer.trainable = True\n",
    "model.compile(optimizer = 'rmsprop',loss ='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "359/359 [==============================] - 134s 374ms/step - loss: 0.0378 - acc: 0.9865 - val_loss: 0.0979 - val_acc: 0.9839\n",
      "CPU times: user 7min 9s, sys: 12.8 s, total: 7min 21s\n",
      "Wall time: 2min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f848c37da58>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(train_generator,\n",
    "                    train_generator.n // batch_size,\n",
    "                    epochs = 1,workers = 3,\n",
    "                   validation_data = validation_generator,\n",
    "                   validation_steps = validation_generator.n // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
